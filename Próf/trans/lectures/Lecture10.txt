0:24  
Right, so today, I'll continue talking about the first word of functional language we had, will do two things. First, and this is kind of tangential, this is just so that you can plug different files together and experiment. I'll comment on how to modify the lexer and parser. For the expressions language we had, so as to also be able to Lex and parse then function declarations and function calls. So that's a minor thing. But then we go on to type inference.

1:07  
So the

1:08  
idea is then to statically check if an expression I've written in my functional language actually makes sense type wise. So work there with integers, Boolean, and first order functions. And we'd like to be sure, before we actually apply the evaluator with our programme makes sense. So I'm not trying to, for example, add together an integer and the Boolean, or maybe I'm not trying to apply a function that is supposed to work on Booleans to actually an integer, this kind of thing. Okay, let me share my screen. And then we get going. Right. So there's two files to play with today. The first one is called first time lexer parser. And then what it does is this lexing and parser functions, for the little extended language, we now have. Just to recall, it is the old language. So we have expressions like we used to have, except that there are these two constructs that are new. so we can write function calls, things of the form f, apply to E, where E is an expression, and f is just a name. Well, it's a name for a function. But on the level of lexing and parsing, we don't know about it, we just look for a name. And then we should be able to to also have these function declared sorry, let constructs where we locally define a function. So they look like this. So, as always, in elite construction, the main thing is, is the body. But then there is this local definition here, we say a function named F is introduced, it has a formal parameter x. And this is then the definition of the function or you also call it the body of the function, not the body of the length, the body of the function here called erhs. Or just for the right hand side. So in abstract syntax, we represent it with a data constructor lectron, that takes four arguments, the function name, the parameter, the right hand side of this local function definition, and the body overlap. So everything else we had before in the abstract syntax, these are the two new ingredients. And our task is to get from concrete syntax for these things like strings of these shapes through Abstract Syntax trees, like these. Yeah, and the game is we deal with this before. So the the actual parser sort of is written in two phases. There is a kind of a preparatory step that is called lexing or tokenizing, where you take a string and you cut it into segments, which are basically are the key words or numerals.

4:25  
Or

4:27  
are there special symbols like parentheses or plus or minus or so? So this face is called lexing, or tokenizing. And then comes parsing proper. So we take a list of tokens and out of that, we need to produce an abstract syntax tree, which is a value in this data type expert expressions as abstract syntax rules. Okay. So all I'm gonna say here is just a little modification on what we did. We could go on Tuesday and Thursday. So I will really just run over it because it's minor modifications. Nothing much else. So the tokens look pretty much the same as before. So these are the kinds of things that we find in in strings, like every now and then we stumble upon a keyword perhaps or, or inequality sign, or we maybe find the numeral. And that is it. So what was the idea of, of the lexer, the idea of the lexer was given a string, walk over it, and you basically work in three different possible modes. Let me see if I can fit all on one slide yours are on one. Exactly. So concentrate now on this bit here. So this is all varies in the lexer, or tokenizer. The idea is to take a string which has already been broken down into a list of characters for simplicity, and turn into a list of tokens. The idea here is these like a little state machine, or automaton, as you might also call, it was basically three different modes, we can either be in the default mode, where we just look at the next character. And, yeah, we try to recognise in it one of a few possible things. And I can comment a bit more on it as we as we go over it. Then the other mode was, we are already in the middle of a numeral. So we've seen maybe a digit, like three or four. So we want to see if there are possibly more digits coming up, that will all together make a numeral. And the third mode tokenized word corresponds to a situation where I'm already in the middle of a word, which can either be a keyword or a name. So I've seen, I think, a lowercase letter that was a sign of the start of a word. And now that it can be more things coming up that are either letters or digits. And as long as these come sort of uninterrupted by spaces, or tabs, or new lines or special symbols, we just carry on and try to collect together the word. So what was the idea? So in the general mode, you see a list of characters about we want to turn it into a list of tokens. If there are no characters left, then we also at the end our token lists, we just finish. Otherwise, if we see one of these sort of operations in moves, then we see say we've seen it. And then we just process the rest of the characters by recursive code, it's very easy. When there is a whitespace, or tab or a new line, then we can in this face, just ignore it, it's just mean some extra space was left. And we carry on tokenizing the rest of the characters is so parentheses that operate in exactly the same way as these operations symbols, we just record the fact that we've seen a left or right parenthesis, like an opening or closing parentheses, we tokenize the rest. But now, if we see a digit, or if we see a lowercase letter, these are signals that we now have to go to a special node. If I see a digit in the general mode, this means I'm at the start of a numeral.

9:04  
So I convert the character to a numeral. And I just tokenize the rest of the characters in this mode tokenize int. And this argument here to the tokenizing, it actually works as an accumulator. So when tokenized int makes further recursive calls, it will be with the new values of the accumulator, where the accumulator has grown with more and more digits that we've seen. And each of those gives us the possibility to to see a bigger pseudo number. So really, this is an integer argument. First, it's just a single digit seen as an integer, but then we can also see multiple digits as an integer. A similar thing happens when we see a lowercase letter in this mode, then we say okay, now this is the first letter of something that's going to be a word and we go to this mode, though. Can I work we try to process the less the rest of characters. And then we say, okay, we can convert the first character to a string. So this single character string is kind of the seed value of the accumulator is the first is the accumulator, the first call to tokenize word. But then the recursive calls again, we will use new values of the accumulator, what have been thrown the, the string argument based on the extra characters we've collected. Right? So how would it tokenizing work I already showed this. So one of the two things can happen, either. The next thing that you see is the digit as well, in which case, you can put this digit together with everything you've seen before. So you take the current accumulator, which is already an integer, you multiplied by 10, which is a position shift, and you add the new digit. So for example, if you had already collected the number 79. And if now digit three comes up, what you do is multiply 79 by 10, get 790 and add three. So the new accumulator is seven 893. So this is the new integer you've seen so far, and more digits may come up. Whenever something else comes up. There is not a digit, so it's either a special symbol, or maybe simply a separator, like special, sorry, like whitespace. Or maybe no some characters come up, then we say the digit has finished here. And we, we just say, okay, the final result of this collection activity was that we've seen an integer whose value is this accumulator. And then we just go back to the default node, and, and, and tokenize, the rest of the characters or all of these characters in that mode. So if the first character is not the digit, we don't throw it away, we just actually go further with all of all of the list of characters that we have here. And word is done completely similarly, except that we don't accumulate a number we accumulate a string. So some string has already been accumulated. And at the moment when I see another character that qualifies for a character appearing in a word, namely, in words, we allow letters and digits, then we just concatenate the newly found character converted to a string to the string already have and we have a longest string, the string act is grown by one letter, or digit. How does lexing or tokenizing then work? Well, given a string, I first have to turn into a list of characters, which is kind of a helper thing. But then we apply tokenized to it. And this is pretty much as before. So now I can, for example, process actually something that has a function call in it. So maybe Lex led x equal x plus three in

13:28  
in what I don't like the five for example. And that should be fine. NVDA indeed it is five, it is fine. So what the lexer says it has seen the keyword let it has seen two names F and X, were considered the separate names not the single name FX because there was a separator here. So when we were looking for this word f then we first looked at the character f then we checked the next character, which was a whitespace. And at that moment, we went from the mode tokenized word back to the regime or mode tokenize the default mode. So when we said okay, since f was not followed by any further characters, f alone already makes a name. Similarly for we found the name x, then the equal sign and another time name x plus integer three, keyword in name, f integer. Okay, there's one thing that I perhaps jumped over too quickly. So there was this thing that when we've collected the word, then we have to decide whether it's a keyword or a name, well, or possibly keywords are here. Any other word that is not the keyword is treated as a name. And we've added a few keywords that weren't there originally like one false or now keywords. I can't remember if we had if then else before, but now we have them in any case. So nothing here. Check Whether the syntax is proper, I mean, I can write any sort of nonsense, for example, I can change the order of these things. Which is obviously, not something that makes sense. But on the level of tokenisation, I can, I can extract some tokens from here, of course, then parsing later will fail, because this left is in a completely wrong place.

15:24  
But on this level, it's fine. Now, how the parsing go, let's remember, where previously, parsing was based on a kind of a description that we call concrete syntax specification, of what kind of strings are meaningful at all, or what kind of already actually tokenized strings are good at all. And this goes by saying wells, these strings could be expressions, or they could be summons or list of summons, or factors or lists or factors. And there was a little grammar for this, since we've added function calls and these function definitions. And the picture will be a bit more complicated compared to what we had before. And also since we added Boolean constants, and also Boolean operations, but it's kind of a new level. So previously, we worked with, with essentially sums of products. So an expression on the top of it was a big sum, made of, you know, summons. And then pluses and minuses. Each summoned was a product made of factors put together with times. And that's because times bind tighter than plus. But here, we also have these comparisons. So really, an expression or the top level can either be like a comparison of two components, or just the simple comprehend. And then these components, each of them can be a sum. So now it's a bit more complicated the overall structure. So an expression on the top level can be a comparison, or maybe a simple, simple compound. Those are actually sums, the summons itself, our products. And then the factors in the products, they are something and then we have to think what and here's a little complication that actually enters. Why? Because, well, this is a functional programming language, and etc. So one of the new things that we want to have in our Abstract Syntax trees, as we already discussed, are function calls that know how are they written concretely, I'd like to be able to write something like this. But there are no parentheses here. And of course, there is sort of morally to play to two places where you might want to put them like one should be this. The other one should be this. So which one do we prefer? Well, we mean, always this, the idea is that function application should bind tighter than plus. But then how to achieve it how to how to organise the parser. So that it tries to also understand factors. Or Yeah. Yeah, so that they will try to understand factors as function calls. And then you get all sorts of interesting questions like, you know, should this be legal syntax? Well, in some sense, we could say it should be because we might say it should mean this thing, because there is no other reasonable way of reading it anyway. To save you've got the function name followed by if, then you should really look, try to parse this if until the end. So to collect an if then else expression, and the whole thing could be an argument. That's the possibility. But then, how about this. So this could mean f apply. This could mean simply, you know, subtraction, which would be to say that f is not the function at all. It's just a name for an integer And we're doing some subtraction that could be possible. But it could also possibly mean f of minus two, where minus is negation, right?

20:15  
And we have to make a decision here. And I will say here, that should always be the preferential reading. So when you apply the function to a negation of something, you'd expect that, that this negation is put in parentheses. That's the only reason, right? So let's see how to achieve this. Well, previously, we had these factors, which were simply a mixture of different things that are here in very different syntactic categories. So we had factors. And if the nails could have been a factor, a normal lead could have been a factor. An integer could have been a factor a Boolean could have been a factor, an expression put in parentheses, which sort of throws us to the top level in this grammar could could be a factor. And that's all well. But now since we do not have a special symbol for function application, there is really two ways or two things that the factor can be the factor can either be a function applied to an argument. Sorry, yeah, a function applied to an argument. And functions here are just names is the first order language. So it should be a name applied to something that is an argument. But it could just be not an application. And one thing we could do is we could say, grammatically, what are all these possible things that are not applications.

22:05  
And also here, the arguments can sort of be general expressions with a difference, that certain sort of general expressions cannot function as arguments, unless they put in parentheses. So let's see. If there is no application situation. So we just have a thing, rather a function applied to a thing, then it could be any of these forms a left or an if, or a negation, or it could be an A, where A is also all the other possibilities, just the name, just an integer, just the boolean value, or an expression in parentheses. But for an application to make sense, we may expect sort of reasonable pronunciation. So we don't want like this guy here to be legal syntax. So therefore, we single out if a something that we can use only zone without parentheses. But if we want to use if, as an argument, then it has to be in the syntactic Category A for an argument. And then you see there is no option for if it can only be achieved by seeing if there's an expression, which is then put in parentheses. So certain things always have to go in parentheses when there are arguments, the negation has to go in parentheses, if it's an argument, a lead has to go there. And if an else has to go there, when it is an argument, so that's one possible way to organise this understanding of what is what is good, concrete syntax. Now, let me remind you how a parser worked at all right. So they're here, the idea was that you define mutually recursively a whole bunch of functions, each one with a particular syntactic category, like the top level one will be for the syntactic category, ie for expressions, but then there will be other ones like parse calm for comparative comparisons, parse some lists for for these ssese, parse summon for summons, etc. And we saw all of that. So there'll be a whole bunch of those many functions. But they all work like this. So let's let's take the main one, for example. So the parse expert has its main purpose to take list of tokens. Turn it into an expression. But it's possible that some tokens are left over. So don't only return an expression, but you return a pair of an expression. And then a list of tokens that you could use, still to parse sort of the rest of the expression that your current expression is embedded in. Now, what was an expression according to the grammar, it can be one of the three forms. So we simply have to try to match the given list of tokens. against these things, to see, each one of these starts with a C. So an expression always starts with a comprehend. And my possibilities are either it is a component followed by equals, or less than and the further comprehend, or it's a component that is not followed by equals, or less than in which case, the component is the whole expression, and the rest of the tokens must be left unfinished. So let's just programme it. Given a list of tokens, I want to parse it as a component for which I have a separate function defined by mutual recursion. I just hope that the call to this function gives me back an expression and the following list of tokens, which are like the residual tokens, then I take those. And I've got three possibilities, either the rest of the tokens begin with equal or less, which means I hope I'm in one of these two cases, and nothing will fail, or I don't see a comparison sign, in which case, I say, Okay, what I return is actually orderly order already came back from this parse conference, together with the rest of the tokens, otherwise, we say, we have to also parse the rest of the tokens as a component. And we hope that then what comes back is a second expression, which is actually a comprehend and more tokens. And we form these expressions, which are the ones that we then collected on this level. And there are some some tokens. And all the other functions are similar. I talked about it at length last Thursday, so I won't repeat it. But let's just go to the important case of factors now, where we have to distinguish between a function application or a factor that is not a function application, which then must be one of these forums that qualify us as heads. So heads are something more specific. Sorry, or something more general than arguments arguments are more limited than heads. heads have arguments is a special case, but not not the other way around. Okay, so this critical place is here.

28:12  
parse,

28:15  
parse vector. So I'm given a list of tokens from which I actually want to get back and expression and some residual tokens. And I'm sort of following this grammar rule. Which says that every factor actually has to be in one of these two forms. So I'll try to figure out which for my having question now. And then I go on.

28:56  
And here there is maybe something special that we didn't see before. So what can I possibly do? Right?

29:24  
Take the list of tokens. And I look at different cases. If the first token is a name, then there is a chance that I'm here.

29:37  
And basically, let's for the moment, ignore this match. Basically, what I should do then is I should take the rest of the tokens these TSS and parse them according to the syntactic category a four arguments. I should then hope that what comes back is an expression for an argument and some remaining tokens and what I then should return is, is the recognition that I've now found the function call where the function name is actually the this first name here. And the argument is the expression I found here. And these are the residual tokens, which would then be good. But there are a bit more options, right? So Another possibility is that, okay, so I don't. So I'm, for the moment ignoring this bit here. I'll come back to this in a second. Actually, I'm also for the moment ignoring this bit here. So this looks like a reasonable thing to do. So if you find the name, then you hope that maybe the next thing that follows is like this. And then everything is great. And if it's not the case, that you find the name, then perhaps you would want to say that, then we just parse everything under the whole thing as a head, and whatever comes back there is also returned as the as the pair of an expression and token list that we do get. So that is the reasonable strategy. But wait, is it really the case? That couldn't, that we couldn't have, that the head also starts with a name, I mean, here, we say that in every case, when the first guy is a name, we go here. And then maybe when we don't find an argument, then we just fail. And we say, this is not the function call. But maybe it's possible. That also for for a head, the first guy that we find is a name, and then perhaps we should do something else. So let's go back to our grandma.

32:09  
So can it be that h also begins with a name. So maybe there is some overlap between these two cases, because here directly we see a name. And here we see h. So h can be all of these forms. But you see, h can also be an A, and an A can be a name, Aha. So there is an overlap here. When we don't find the function called maybe it's just, you know, a single name. So then how do we organise the parsing so that if we went for this option, then we don't have to regret when we fail. And we'd need to backtrack and come back to this option? Well, we should maybe do a bit of analysis then. So because let's just let's just see, which are the possibilities when the A can be a legal argument. If it is a legal argument, it has to be a name. Okay, in which case, we can recognise that we have a function call. Once we've seen two names in a row,

33:27  
or

33:28  
it can be integer, but integers are, are very easily recognised, because they have to be something of the form into whatever but it can if it's Boolean, then it we know it has to be true or false. Like if it's a Boolean constant. And if an argument begins, is an expression in parenthesis, then there is also a clear sign of it. I mean, it really has to begin with, with parentheses. So these are the only cases when we should say, Okay, yeah, we think we are here. Because you see, a head cannot be a four B of a form a name followed by one of these things. So let's incorporate that knowledge in our code. And then we avoid backtracking which would need to be processed otherwise. So what was our perspective?

34:26  
Yeah, we have to be here.

34:29  
So I said, At first, I didn't want to look at these these guys. But now I want to. So so this is simply to say. There is hope that this is a function call. If actually,

34:53  
the argument begins with a name which then me The argument is a name, or it is a numeral, or it is one of the Boolean constants, or it is parentheses. So this is just to check if there is any hope that, you know, we are in this case, really. So we want to be sure that that we are going down this route, if there is hope for this, and at the same same time, this is cluded, in this situation that we're here, because whenever we got the name followed by another neighbour name, followed by an integer name followed by through, it's clear that we shouldn't go in this case. So it's really saying either this one will succeed. Or we are completely doomed. So the whole parsing of the fingers as if faith, because we know already that we can't be in this cake. But then there is also the possibility that we already decided that the first guy is a name. And the second thing isn't an argument, then we should sort of take the special case that age is actually a single name, it's just the variable. And sort of move it over to this case, because we don't want to do any backtracking. So we say if it is a name, and it's not followed by any one of those, then let's say straightforwardly at this stage, that this is just the case that we didn't find a call, but we found just the use of, of, of like a normal variable, like first order variable, so a variable for for a number or a string. Okay. Then we're done. This is parsing, and then I can I can show this in action. So if we take something like this here, and we combine it with parsing for this, the function is Lex parse, it just calls the lexer and parser in a row.

37:01  
That should be reasonable codes, we should get the proper answer back. But we don't why did this happen? Because I took the wrong one.

37:12  
Yeah, this one is the one where we want to listen to experts. So we see that the guy properly understands that this is a function definition, let, so we're left with a local function definition, the function name is F, the parameter is x. The function definition itself is this guy, the function body, so to say, and that's the body of, of the whole let fun, which is just a function call. And then the one that we saw failing, there was the one where things were in the wrong order. So when we see something like this, because of its shape, I mean, the whole thing, where if you if you go through the parser, has to be effector. So here we see a name, then we see a following name. And that could be like a function application. And that would be perfect. But after that, there is some trash, I mean, there is some part of part that we cannot consume. And then we when we call the function, it says unconsumed tokens. Okay. So we could sort of go in finer detail. I've got some more functions here. So So what actually happened was Lex parse calls the lexer and the parser. And the parser wants that there are no leftover tokens. But if we go in smaller steps, I could use the function pars on just Lex and then we see a bit more information. So let me just call Lex of this thing. When I apply parse to the result, and this one will actually just return a pair

39:04  
of something that it found, hopefully, plus all of the leftover tokens, and let us see if we now have more luck. And I would say we should have more luck, because what will come back should be something that we can extract from here when we just start from the left like a function call. And then there should be that complaint that you know this part is left over.

39:32  
This is not called parse. I'm sorry, this one will also check that it's not its parse expert.

39:41  
Is it called parse expert.

39:44  
Yes, the top level is called parse expert. And now what comes back is an expression but there are also some unconsumed tokens. And you can see when you start parsing this from the left, you can reasonably extract an expression That's no problem. We say this is f call that x. But then the rest is left over. And this is what the function parse, doesn't tolerate, to parse, calls parse expert and then checks that the leftover list of tokens is empty and throws it away. So this one fails, but this one just gives us gives us what is left over at this stage. Okay. So this is lexing and parsing. Now let me go to something else, which was typing.

40:43  
So

40:44  
let's work with this language. Again, it's still the same language, sort of. But I'd like to know that following play the following game, I'd like to make sure that an expression makes sense, not only syntactically. But sort of semantically, in the sense that if I were to evaluate, I shouldn't get sort of runtime errors for for the type mismatch reasons. Like, it shouldn't happen during the runtime that I'm trying to add it together, say, a Boolean or an integer, or it shouldn't happen during the runtime that I'm trying to call a function that once the Boolean has an argument on an expression that actually evaluates to an integer. So we'd like to avoid these things. Yeah, avoiding these things ahead of time avoiding this ahead of actually executing or running programmes or evaluation, as we say here. It's called static piping. Yeah. So in languages with static typing, you refuse to run dangerous programmes. And programmes are called dangerous when they can give you these type errors during runtime. These are errors that differently from some other type of errors could be foreseen before you even run. And then this is like a reasonable precaution to take, yeah, avoid running dangerous or unsafe

42:19  
programmes.

42:22  
So what I'll do now, today, is not real type inference, which would work like f sharps own, so you don't write any type annotation. And the system just figures out the types for you. I'd like to do kind of a combination of type inference, which is the system figures out types versus checking, which is you also give your hints about types. And then to see if you agree with the system. So we do this kind of combination of inference and checking. A nice combination of inference and checking is is, is obtained when you're slightly modify the syntax for for function length. So remember, we had these function LEDs that took a function name, the parameter, the right hand side, defining then the function and the body of the whole length. And I'm just putting rec in parentheses to, to indicate that we actually understood this length as kind of lead rec in the sense of F sharp, so recursion is allowed. And let's just do a similar thing that is also allowed in F sharp we, we we can annotate our parameter with the type that we intend is reasonable for this function. So the function is supposed to work well with input of that type. And we also give an output type or the return type for the function as an annotation or as a hint. And we put these hints everywhere. So this means in concrete syntax, really, it looks like this. So you can actually write expressions, Allah, Allah this. So here is the here is a little app that is properly annotated, we're saying the input is of type int, the output is of type int, it has a definition, and then maybe there is a function call. So we work like this. And on the level of abstract syntax, then these type annotations are also captured. So let's run takes more arguments. Previously, it only took the function name, the parameter, the right hand side of the function defining the function and the body of the LED. Now it also takes the input type and the output type. The literal will come in the same order as they are given here. Okay. So what does it mean? It means that my type of abstract syntax trees for expressions is modified in one place. So let's find doesn't only take two names, and two expressions, but it also takes two types as arguments. Now, what can types be Well, hearing this language types can be either integer or Boolean. And these are the only ones that we can manipulate those values. But what we also have around our function names and function names actually represent well functions. And so therefore, we also put function types here. So we allow these kind of function types.

45:32  
Okay, and what's the game now? We would like, for example, to write a programme called infer, which takes an expression. And it's supposed to return its type or fail when it cannot properly be typed. And, for example, on this expression, in parse form, so given the abstract syntax tree for this guy, it should just tell us, this is a perfectly good programme. And when you run it, you get back an integer, well, which is a good prediction, because when you run it, you actually get back 14, which is an integer. And type inference should should figure it out by not trying to actually calculate, but only do little checks. Like here, we should try to understand if this thing is well timed. Well, how do we figure it out? Well, we put the hint that we are only ever gonna call it on integers. So we can assume that x here is an integer 11, we know is an integer, we know that adding together two integers is correct and gives a as a result, an integer. And this knowledge agrees with what we've said about the function. So at this place, we infer the type of the right hand side and we check that the degree is actually what the user has said. So that's one particular place of sort of inference and checking combined. And then we go to the body. For the body, we do, what is the body is a function application. So by the time we reach here, we know that f is of type integer int, then we infer the type of the argument here, it's very easy to see the three is an integer, and then we have to check that the declared input type of the function and the actual inferred type of the argument agree.

47:29  
It is the case here. So the argument is int, the input type of f is int. And then we say the whole thing has this type,

47:35  
the owl type, the output type of F here, because it's a function call, so therefore, the the type of the whole thing is an integer. Yep, that should be the mechanism. But if you were to discover some nonsense, like you're trying to add together to 111, then you say, okay, Boolean Plus, it doesn't make sense, then you fail, or maybe signal an error. Now, this type inference is easy, easily implemented by basically mocking, ordinary evaluation. But when in evaluation in an environment, you keep values of the variables currently in scope, and you find the value of the expression you're processing in inference in the environment, you just keep abstractions of these values. So for every variable, you just remember what its type is. And for the expression that you're currently processing, you also just remember or infer, the type it obtains. So raw is like evaluation, but the evaluation not on the level of, of actual values, but just on the level of pipes. Yeah, it just propagate pipes around in your programming or expression. And you try to see if everything works, or do you actually get stuck at some point, because you're trying to do something to apples and oranges. Which doesn't fit. Uh huh. So, in the case of so now what I do is I generalise The, the type of environments, previously, environments were just lists of pairs of strings and values. But now it's good to work with a sort of general notion of environment. So an environment can be a dictionary or whatever. So I can pair together strings and values to get the dictionary or to get an environment for values but I can also pair together strings and type names. And then I get the dictionary that I can use in my type inference. And I'm more or less give you the idea of type inference, there is one one further nuance, which is that if you do something like type inference say for if the nails then else Then, since before you execute the programme, you don't know which brand service will be taken. But you need to figure out the type for the whole, if you just do something that is different from what you're doing evaluation evaluation, you always go down one branch, namely the correct branch for the given Boolean statically. The Boolean doesn't have a known value, therefore, you have to try both branches. To realise like non deterministic choice, if you wish between two branches, as we say that we get a good time for if then else, only if whichever branch is taken, so only if in both cases, we do get back exactly the same time. Otherwise, we say there is some sort of contradiction in the if then else in the sense that, for example, here, if x is smaller than y, we know that this whole thing that then we go to the two brands, this one has type int. So therefore, the whole thing as typing. If x less than equals false, we go to this branch, we say false, this one has type bool. Therefore the whole thing has type bool. So statically, we don't know whether the whole thing now has type integer, a bool. Therefore we say this is Ill type. And that's reasonable thing to do. Because suppose this, if we're part of a bigger thing, maybe I wanted to add 17 to it. We really don't know whether this is safe. This programme is safe. If I am sure that I always go to the left branch because then the value is just 20. But if there is a slightest chance that I may need to go to the right branch, then I do get false plus 17, which is which is ill formed. Yeah. And since statically, statically means ahead of execution, I can't know which branches are taken, I should prepare myself for the worst, namely that both branches are possible in unfortunate cases. And I only say I'm safe, if in every case, things work out nice. Yeah. Right. So let's, let's get to the inference. As I said, inference, really is like evaluation, it's very important to realise this, at least in this case, when we have these type annotations around varies a bit of difference from evaluation in how you work with function calls and let fun. But we'll get there, essentially, you'll see that there will be no need for closures.

52:38  
And there is a reason for this. But otherwise, there is nothing very mysterious going on. Right? So what does inference do inference takes in an expression, and if it successfully evaluates, then what should come back is a type so knowledge that this expression is an integer or a Boolean? Well, if the language were higher or equal, theoretically, also be a function. But here, no, this kind of actually occurred because we can't use functions as values. And then there is this help of xillia argument environment. So this is where we recall the types of the global variables but also the types of all local variables, which can then be ordinary variables and functions. Okay. How does type inference go? If I see an expression that is actually a variable, then I just look it up in the environment. And if the environment says the variable has this type, then that's what we return. If the environment for some reason says that the thing is a function, then we say we're trying to use a function as a value, and that should be forbidden. And we say, well, in a harder language, you will be fine in this case, but here we just explicitly forbid it. Okay, then, what do we do for some simpler cases, let me jump over, let them call

54:08  
them let fun. So when you see a numeral, then you can straight away say this is a numeral. When you see a plus, then what you need to do. And that's now very similar to evaluation. In the case of plus and evaluate, you have to evaluate both summons, these had to be numbers. If they were numbers, you could add them together. Now we don't do the actual addition we just infer the type for the first summon for the second summon. If type inferences, they're both integers, I say fine, the result is then also an integer. Otherwise, for every other possible combination, like one argument is an integer The other is bool. Or one is bool. The other is integer or both a bool. We just fail and we say these arguments are not good. Similar for miners and payment negation. How about some Boolean stuff

55:05  
Well, the Boolean constants are of type bool. When I, for example, want to check equally the E one equals e two, five, check that. How does that work? Well, I have to infer the time both for you one and the two. These must be integers, because we only allow a comparison of integers. But the result we say then is an interesting case if then else. How do you do that? Well, first of all, it is mandatory that he comes out as Boolean, we infer the type three, and we hope it's Boolean. If it's Boolean, then we carry on and do something. If it's not Boolean, then we say the guard is not the Boolean. So that's already very bad. Otherwise, if this guy is Boolean, then there is hope that they the whole if then else has a good time, what time we just discussed this, for if they if then else to be well timed. Both branches have to have the same time. So whichever is taken, the venue should come out the same time and then that time is the time for the whole if then else. So what do we do is we infer the types of both e one and E two, let them be, say T one and T two. If they're equal, then we say, well, T one is the type of the whole thing. I could also say T two here the equal otherwise we say, if then else Bronte's are of two different types. So that's an error. We're basically done now. Now there are only the interesting cases left. Now the simple let differently from lead fun is also very, very similar. How would the devaluation for lead? So what was the point there? When we did the evaluation, the value of the lead is basically the value of the body. So here, the type of the lead is basically the type of the body. But the body can operate with one more variable than the lead itself, because there is a local variable. Yeah. So then in which environment, should I infer the type of a body? Not exactly the same environment and in which I evaluate the length? No, because it has to be an extended environment, where I already know that the new variable x, that kind of a key occur in the body has some certain type. So what should I do? It's again, very similar to evaluation in the evaluation, you need to actually, even before you get to the body, you have to evaluate the right hand side, there, you find the value of the right hand side, and then you record it in an extended dictionary or environment, that this value is now the value of x here, we do exactly the same thing, but not on the level of values, but types. So in with infer the type on the right hand side here. And then we say, Okay, this is gonna be the type of x and we put it in the environment, the new environment, and that's where we evaluate the body pump done. Now, at that stage, I can already do a few things. So I can show you a bit of this. Here it goes. Let's do some simple type inference. So for example, when I want to infer the type of say numeral three, what is it? That can be done in the empty environment? This is an integer. What if I just want to know what the type of true is? That is a Boolean. Great. What is the type of plus num? Three? Five. That's also an integer. How did it work? Well, no three had type int, num five had type int. Then when we looked at plus we use these inferred pipes and we said okay, since they're both in the result is good. How about that now, we want to add together num, three and false. We get to know arguments of plus or not integers. So in particular, the second argument is not an integer. And that's what we called it up here, right? It's the place

59:44  
to place this place. Yep. Okay, let's have some variables around. So if I just do in for var x in the empty environment, what can happen? Well Similar to evaluation, if you don't give the value to x in the global variable x in the environment, then the whole thing must simply give up because it has no idea what the value would be. Here, we have no idea what the type could be. We say x not found in the environment. Okay? If we say x is of type int in the environment,

1:00:26  
then it says, Okay, great, then var x is an integer. If I say x is a Boolean, that says great. X is a Boolean, so I determining because it's a global variable. No, suppose I said, This guy was an integer, then I can actually do the old thing. I can do plus var, say, No, whatever, no four. And it is an integer, because from the environment, we'll learn x is an integer, then we can add these things together. But as soon as I say x is Boolean, now, I get back to the old problem arguments of plus or not integers. Where did this come from? Well, four is an integer. But x isn't an integer according to what I've said. And of course, the same also works if I have a local definition. So if I have something like, let x be numeral three, in this whole thing,

1:01:28  
then I'm sort of locally fixed that x is an integer, the system can figure it out. And then we say, Okay, I'm adding together an integer and integer that should be fine, the result should be an integer. And that's what we see. But the moment I here say, Let X be false, in plus of x and four, then it will complain again, for the same reason, arguments of plus are not integers From where did it come now, in the original dictionary, there is no type given for x. But the point is, when we evaluate or sorry, when we type in for length, then we extend the environment here with this knowledge that x is of type bool. Because the inferred type for x is bool. And that's what happens. Yep. What remains are functions. So function calls and let fun. And now the interesting thing is when we did function definitions, local function definitions and function calls, then the what we had to store as a value function was a closure. So we had to remember the, the values of, of the non local of the non local variables or function definitions that must have come from somewhere else. So that was called the closure. So store the current environment. Here, it is actually not needed. Because we've got enough information in these type annotations, to recall everything. So the point is, in evaluation, we actually never evaluated the body before a function call, before an actual function call, which is syntactically stored in the expression for the function together with the environment, that's called the closure

1:03:27  
as the sort of meaning of the function here, we can check a function locally. At the at the moment when a function is defined,

1:03:39  
and add a call since the type information is there, we don't have to sort of revisit the function body anymore at all. And there is very little else to do. So let me see. Let, let's see. So what do I need to do when we have a function call? So F and E are? When we look up the function in the environment, the environment has to say that it's at f is a function type with say, input type T and occupy t prime. One all I need to do is I infer the type of the actual given argument. And I see if it agrees with what the functions declared input type is from the annotation. Yeah. If it is, then we say that the result of the function call is just the output type of the function. So we trust that the function does the right thing on the level of types is best that's not checked here the call let's check that the function definition side. So if the call argument is not of declare type, then we fail. And of course, we also fail when the thing that we call is not even a function. Like we tried to call a number on an argument or we tried to call To find out what happens at let fun, let fun now looks like this, which corresponds to this piece of concrete syntax. Well, similar to let the type of the whole length is the type of the body, so we just have to infer the type of the, of the body. That's the main thing to do. But now, again, not in the original environment, but in some extended environment, that would actually know what the type of f is. Oh, sorry, this is what I tried to simplify. Okay. So we have to infer, now that's correct, we have to infer the body in a kind of an extended environment where we also say what the what the type of the function is. And we get the type of the function simply from the declaration, we see that we've stated that the input has to be of this type, the output then will be of that type. So we add this to the environment, the new environment is called n prime. And this is where we derive the type of the body. So that's on the level of inference, but we should also check that the body is okay, I promise that I checked, check everything about the body at the function definition site. So let's do this. Here's the definition of the function what can the definition of the function referred to compared to end the function definition of course, can work with the parameter and it can also work with recursive calls to the same function. So, we should check we should type the sorry, we should infer the type of the right hand side. So this function definition in unextended environment, and this time, the extended environment should contain both the knowledge about the type of the function for recursive calls, but should also contain the knowledge about the argument of the function. So in refer when further type of the function definition, and this must then agree with a type of with a declared output type. So then we say, if this is not the case, then we don't return anything meaningful, then we actually instead say we we say the lead fund function body is not of the declare type. So there is a mismatch between the declared output or return type. And what we actually see here. Okay, that is actually completes the thing. Now we can check some more useful functions. So so this is the abstract syntax tree for a very little thing that I already talked about. And what should really happen is, as I as I described, so at the moment, when the function is defined, I should check that this thing here really is an integer as we purport that it is.

1:08:39  
And that's done by extending the environment. So adding to the environment, the knowledge that x is integer, also adding it to the environment, the knowledge that F itself is of type int to int, for recursive call, but here, we don't have any, but in general, we might have. So we do this check locally that everything is fine. And then we actually called site, we only check that the argument conforms to the declared input type of a function. So let's do that one. Um, so the the whole thing is called you one. There is a here, let's do type inference for it. We can do it in the empty environment, since there are no global variables. And we say it says integer. Now it's, yeah, here is perhaps difficult to see what what actually was done, but let's modify the tiny bit. So one of the modifications we could do is we call F on the wrong argument. So maybe I haven't. Okay. So let's call it on a modified thing. So I don't directly use this but I'll use something else.

1:10:11  
Maybe I want to call F on something wrong. So let me call F on Ponce tool. And then what does it say call argument not on declared tight. So we are now in this place where, where then error came from here. So I'm, I'm having this function call here, f apply to true if he's actually declared to be of type int to int, so the empty primary here are int. And then what we do is we check if the if the if the argument actually admits this type. So if we infer the type for the argument here, false, if it then agrees, the type for false is more, or is not equal to it. Therefore we say the call argument is bad. Let the call argument be good. Let's do a modification at a different place. So what was it here? It was, say num three. But let me edit the different place. Let me just say the wrong thing here, about the input type. Let me pretend that the function takes a Boolean to an integer. Now, what do you think will happen? Well, something should happen when the function body is checked, because now this will happen in an environment where we say, x is Boolean, and then type inference to this. So tell me that in the body here, I'm trying to add together a Boolean and the number and an integer and that should be not allowed. And indeed, this is what we say we say, arguments of plus not integers. So that's one way to say, Okay, let's do one final one. Let me have the correct input type. But let me purport I have a bad output type.

1:12:28  
Yeah. Now, from the point of view of the call, everything should be fine, right? Because I'm applying F, which is a function that takes an int and returns a bool to a number. So three is an integer, that should be fine. And the result should therefore be bool. From the point of view of the call, but there is a different problem. The problem is, the problem is that I'm declaring the wrong type, right? Because adding an integer with 11 gives back another integer. Not cool. So now we should have the complaint that something is wrong with a function definition. And let's see what it says it says, Let fun function body not have declared type. So we are in this situation where this ID card is false. Okay. So now we could try to fix this. So let's properly have a function that sends any future to Boolean. So I could do this by for example, using equals, or what is it called? For equal or equals, I could, for example, use less. So let's instead of plus useless, we're checking if x, which is an integer is less than 11, which is also an integer. How are things now? Now perhaps everything should be good, because this is properly here, a function from int to pool, as I'm saying. And then when I apply f two, three, it should return a Boolean, because I'm, after all, applying a function that takes an integer to a Boolean, num, sorry, three is an integer, so that should be good. We've actually evaluated it, we would check whether three is smaller than 11, which is true. But statically. We don't care if it's true or false, we just care whether a Boolean comes out. When we do this, we see a Boolean comes up. So that's what we did today. So I've shown you two things. One is how to modify the lexer and parser. And the only little challenge there was in the positive part, where we had to do a bit of a look ahead to avoid backtracking in the case where sort of on a on a shallow level, which was not immediately possible to determine which one of the two cases for a factor should apply for the given list of tokens. And here, in the second file, we talked about, sort of type inference for a modified version or functional language where we actually annotated Local function definitions with types. So these are something that the type inference can use as hints on the other hand, but it. So for example, figuring out the type of right hand side, we can already use the knowledge about what the type of the parameter is rather than having to guess it. But this also means inference is not just inference, but we also do some checking. So we should check that the annotations actually make sense that they're sort of consistent between each other. Okay, and that was it for now. I'll stop sharing. And I'll also actually say good bye

Transcribed by https://otter.ai
